{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxTiuLtBfG_k",
        "colab_type": "text"
      },
      "source": [
        "FaceNet: AUniï¬edEmbeddingforFaceRecognitionandClustering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzOd99_zfbnT",
        "colab_type": "text"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTHmt61vfE0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import model as embedding\n",
        "import torch\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LEECKCVJtmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#upload model.py, deploy.prototxt.txt, res10, dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsOcygsQ7SfS",
        "colab_type": "code",
        "outputId": "1d5a3bfa-3cf4-40e7-96ac-8fcf92945a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip dataset.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  dataset.zip\n",
            "   creating: dataset/APJ Abdul Kalam/\n",
            "  inflating: dataset/APJ Abdul Kalam/kalam-1.jpeg  \n",
            "  inflating: dataset/APJ Abdul Kalam/kalam-10.jpg  \n",
            "  inflating: dataset/APJ Abdul Kalam/kalam-2.jpeg  \n",
            "  inflating: dataset/APJ Abdul Kalam/kalam-3.jpeg  \n",
            "  inflating: dataset/APJ Abdul Kalam/kalam-4.jpeg  \n",
            "  inflating: dataset/APJ Abdul Kalam/kalam-5.jpeg  \n",
            "  inflating: dataset/APJ Abdul Kalam/kalam-6.jpg  \n",
            "  inflating: dataset/APJ Abdul Kalam/kalam-7.jpg  \n",
            "  inflating: dataset/APJ Abdul Kalam/kalam-8.jpg  \n",
            "  inflating: dataset/APJ Abdul Kalam/kalam-9.jpg  \n",
            "   creating: dataset/Ashwin/\n",
            "  inflating: dataset/Ashwin/ashwin-1.jpeg  \n",
            "  inflating: dataset/Ashwin/ashwin-10.jpg  \n",
            "  inflating: dataset/Ashwin/ashwin-3.jpg  \n",
            "  inflating: dataset/Ashwin/ashwin-4.jpg  \n",
            "  inflating: dataset/Ashwin/ashwin-5.jpg  \n",
            "  inflating: dataset/Ashwin/ashwin-6.jpg  \n",
            "  inflating: dataset/Ashwin/ashwin-7.jpg  \n",
            "  inflating: dataset/Ashwin/ashwin-8.jpg  \n",
            "  inflating: dataset/Ashwin/ashwin-9.jpg  \n",
            "   creating: dataset/B kumar/\n",
            "  inflating: dataset/B kumar/bk-10.jpg  \n",
            "  inflating: dataset/B kumar/bk-2.jpg  \n",
            "  inflating: dataset/B kumar/bk-3.jpeg  \n",
            "  inflating: dataset/B kumar/bk-5.jpg  \n",
            "  inflating: dataset/B kumar/bk-6.jpg  \n",
            "  inflating: dataset/B kumar/bk-7.jpg  \n",
            "  inflating: dataset/B kumar/bk-8.jpg  \n",
            "  inflating: dataset/B kumar/bk-9.jpg  \n",
            "   creating: dataset/bumrah/\n",
            "  inflating: dataset/bumrah/bumrah.jpg  \n",
            "  inflating: dataset/bumrah/bumrah-1.jpg  \n",
            "  inflating: dataset/bumrah/bumrah-10.jpg  \n",
            "  inflating: dataset/bumrah/bumrah-4.jpg  \n",
            "  inflating: dataset/bumrah/bumrah-5.jpg  \n",
            "  inflating: dataset/bumrah/bumrah-6.jpg  \n",
            "  inflating: dataset/bumrah/bumrah-7.jpg  \n",
            "  inflating: dataset/bumrah/bumrah-8.jpg  \n",
            "  inflating: dataset/bumrah/bumrah-9.jpg  \n",
            "   creating: dataset/dhawan/\n",
            " extracting: dataset/dhawan/dhawan-1.jpeg  \n",
            "  inflating: dataset/dhawan/dhawan-2.jpeg  \n",
            "  inflating: dataset/dhawan/dhawan-3.jpeg  \n",
            "  inflating: dataset/dhawan/dhawan-4.jpeg  \n",
            "  inflating: dataset/dhawan/dhawan-5.jpeg  \n",
            "  inflating: dataset/dhawan/dhawan-6.jpg  \n",
            "  inflating: dataset/dhawan/dhawan-7.jpg  \n",
            "  inflating: dataset/dhawan/dhawn-10.jpg  \n",
            "  inflating: dataset/dhawan/dhawn-8.jpg  \n",
            "  inflating: dataset/dhawan/dhawn-9.jpg  \n",
            "   creating: dataset/dhoni/\n",
            "  inflating: dataset/dhoni/dhoni-1.jpeg  \n",
            "  inflating: dataset/dhoni/dhoni-10.jpg  \n",
            "  inflating: dataset/dhoni/dhoni-2.jpeg  \n",
            "  inflating: dataset/dhoni/dhoni-3.jpeg  \n",
            "  inflating: dataset/dhoni/dhoni-4.jpeg  \n",
            "  inflating: dataset/dhoni/dhoni-5.jpeg  \n",
            "  inflating: dataset/dhoni/dhoni-6.jpg  \n",
            "  inflating: dataset/dhoni/dhoni-7.jpeg  \n",
            "  inflating: dataset/dhoni/dhoni-8.jpg  \n",
            "  inflating: dataset/dhoni/dhoni-9.jpg  \n",
            "   creating: dataset/DYPatil/\n",
            "  inflating: dataset/DYPatil/DYPatil.jpeg  \n",
            "  inflating: dataset/DYPatil/DYPatil-1.jpeg  \n",
            "  inflating: dataset/DYPatil/DYPatil-10.jpg  \n",
            "  inflating: dataset/DYPatil/DYPatil-2.jpeg  \n",
            "  inflating: dataset/DYPatil/DYPatil-3.jpeg  \n",
            "  inflating: dataset/DYPatil/DYPatil-4.jpeg  \n",
            "  inflating: dataset/DYPatil/DYPatil-5.jpeg  \n",
            "  inflating: dataset/DYPatil/DYPatil-7.jpg  \n",
            "  inflating: dataset/DYPatil/DYPatil-8.jpg  \n",
            "  inflating: dataset/DYPatil/DYPatil-9.jpg  \n",
            "   creating: dataset/jadeja/\n",
            "  inflating: dataset/jadeja/jadeja-1.jpg  \n",
            "  inflating: dataset/jadeja/jadeja-10.jpg  \n",
            "  inflating: dataset/jadeja/jadeja-2.jpg  \n",
            "  inflating: dataset/jadeja/jadeja-3.jpg  \n",
            "  inflating: dataset/jadeja/jadeja-4.jpg  \n",
            "  inflating: dataset/jadeja/jadeja-5.jpg  \n",
            "  inflating: dataset/jadeja/jadeja-6.jpg  \n",
            "  inflating: dataset/jadeja/jadeja-7.jpg  \n",
            "  inflating: dataset/jadeja/jadeja-8.jpeg  \n",
            "  inflating: dataset/jadeja/jadeja-9.jpeg  \n",
            "   creating: dataset/modi/\n",
            "  inflating: dataset/modi/modi-1.jpeg  \n",
            "  inflating: dataset/modi/modi-10.jpg  \n",
            "  inflating: dataset/modi/modi-2.jpeg  \n",
            "  inflating: dataset/modi/modi-3.jpeg  \n",
            "  inflating: dataset/modi/modi-4.jpeg  \n",
            "  inflating: dataset/modi/modi-5.jpeg  \n",
            "  inflating: dataset/modi/modi-6.jpg  \n",
            "  inflating: dataset/modi/modi-7.jpeg  \n",
            "  inflating: dataset/modi/modi-8.jpg  \n",
            "  inflating: dataset/modi/modi-9.jpg  \n",
            "   creating: dataset/Obulapathi/\n",
            "  inflating: dataset/Obulapathi/obulapathi-1.jpeg  \n",
            "  inflating: dataset/Obulapathi/obulapathi-2.jpeg  \n",
            "   creating: dataset/prabhat_ranjan/\n",
            "  inflating: dataset/prabhat_ranjan/prabhat_ranjan-1.jpeg  \n",
            "  inflating: dataset/prabhat_ranjan/prabhat_ranjan-2.jpeg  \n",
            "  inflating: dataset/prabhat_ranjan/prabhat_ranjan-3.jpeg  \n",
            "  inflating: dataset/prabhat_ranjan/prabhat_ranjan-4.jpeg  \n",
            "  inflating: dataset/prabhat_ranjan/prabhat_ranjan-5.jpeg  \n",
            "  inflating: dataset/prabhat_ranjan/Prabhat-10.jpg  \n",
            "  inflating: dataset/prabhat_ranjan/prabhat-6.jpg  \n",
            "  inflating: dataset/prabhat_ranjan/Prabhat-Ranjan-8.jpg  \n",
            "  inflating: dataset/prabhat_ranjan/PrabhatRanjan-9.jpg  \n",
            "   creating: dataset/prasad/\n",
            "  inflating: dataset/prasad/prasad-1.jpg  \n",
            "  inflating: dataset/prasad/prasad-10.jpg  \n",
            "  inflating: dataset/prasad/prasad-2.jpg  \n",
            " extracting: dataset/prasad/prasad-3.jpeg  \n",
            "  inflating: dataset/prasad/prasad-4.jpg  \n",
            "  inflating: dataset/prasad/prasad-5.jpg  \n",
            "  inflating: dataset/prasad/prasad-6.jpg  \n",
            "  inflating: dataset/prasad/prasad-7.jpg  \n",
            "  inflating: dataset/prasad/prasad-8.jpg  \n",
            "  inflating: dataset/prasad/prasad-9.jpg  \n",
            "   creating: dataset/Rahane/\n",
            "  inflating: dataset/Rahane/rahane.jpg  \n",
            "  inflating: dataset/Rahane/rahane-1.jpeg  \n",
            "  inflating: dataset/Rahane/rahane-10.jpg  \n",
            "  inflating: dataset/Rahane/rahane-2.jpg  \n",
            "  inflating: dataset/Rahane/rahane-5.jpg  \n",
            "  inflating: dataset/Rahane/rahane-6.jpg  \n",
            "  inflating: dataset/Rahane/rahane-7.jpg  \n",
            "  inflating: dataset/Rahane/rahane-8.jpg  \n",
            "   creating: dataset/raina/\n",
            "  inflating: dataset/raina/raina-1.jpg  \n",
            "  inflating: dataset/raina/raina-10.jpg  \n",
            "  inflating: dataset/raina/raina-2.jpg  \n",
            "  inflating: dataset/raina/raina-4.jpg  \n",
            "  inflating: dataset/raina/raina-5.jpg  \n",
            "  inflating: dataset/raina/raina-6.jpg  \n",
            "  inflating: dataset/raina/raina-8.jpg  \n",
            "  inflating: dataset/raina/raina-9.jpeg  \n",
            "   creating: dataset/rohit/\n",
            "  inflating: dataset/rohit/rahit-1.jpeg  \n",
            "  inflating: dataset/rohit/rohit-10.jpg  \n",
            "  inflating: dataset/rohit/rohit-2.jpeg  \n",
            "  inflating: dataset/rohit/rohit-3.jpeg  \n",
            "  inflating: dataset/rohit/rohit-4.jpeg  \n",
            "  inflating: dataset/rohit/rohit-5.jpeg  \n",
            "  inflating: dataset/rohit/rohit-6.jpg  \n",
            "  inflating: dataset/rohit/rohit-7.jpg  \n",
            "  inflating: dataset/rohit/rohit-8.jpg  \n",
            "  inflating: dataset/rohit/rohit-9.jpg  \n",
            "   creating: dataset/sachin/\n",
            "  inflating: dataset/sachin/sachin.jpeg  \n",
            "  inflating: dataset/sachin/sachin-10.jpg  \n",
            "  inflating: dataset/sachin/sachin-11.jpg  \n",
            "  inflating: dataset/sachin/sachin-12.jpg  \n",
            "  inflating: dataset/sachin/sachin-2.jpeg  \n",
            "  inflating: dataset/sachin/sachin-3.jpeg  \n",
            "  inflating: dataset/sachin/sachin-4.jpeg  \n",
            "  inflating: dataset/sachin/sachin-5.jpeg  \n",
            "  inflating: dataset/sachin/sachin-6.jpeg  \n",
            "  inflating: dataset/sachin/sachin-7.jpg  \n",
            "  inflating: dataset/sachin/sachin-8.jpg  \n",
            "  inflating: dataset/sachin/sachin-9.jpg  \n",
            "   creating: dataset/shewag/\n",
            "  inflating: dataset/shewag/sehwag-1.jpg  \n",
            "  inflating: dataset/shewag/sehwag-10.jpg  \n",
            "  inflating: dataset/shewag/sehwag-2.jpg  \n",
            "  inflating: dataset/shewag/sehwag-5.jpg  \n",
            "  inflating: dataset/shewag/sehwag-7.jpg  \n",
            "  inflating: dataset/shewag/shewag-3.jpeg  \n",
            "  inflating: dataset/shewag/shewag-4.jpg  \n",
            "  inflating: dataset/shewag/shewag-6.jpg  \n",
            "  inflating: dataset/shewag/shewag-8.jpg  \n",
            "  inflating: dataset/shewag/shewag-9.jpg  \n",
            "   creating: dataset/Umesh/\n",
            "  inflating: dataset/Umesh/umash-10.jpg  \n",
            "  inflating: dataset/Umesh/umash-2.jpg  \n",
            "  inflating: dataset/Umesh/umash-3.jpg  \n",
            "  inflating: dataset/Umesh/umash-4.jpg  \n",
            "  inflating: dataset/Umesh/umash-5.jpg  \n",
            "  inflating: dataset/Umesh/umash-6.jpg  \n",
            "  inflating: dataset/Umesh/umash-9.jpg  \n",
            "   creating: dataset/viratKohili/\n",
            "  inflating: dataset/viratKohili/vk-1.jpeg  \n",
            "  inflating: dataset/viratKohili/vk-10.jpg  \n",
            "  inflating: dataset/viratKohili/vk-11.jpg  \n",
            "  inflating: dataset/viratKohili/vk-2.jpeg  \n",
            "  inflating: dataset/viratKohili/vk-3.jpeg  \n",
            "  inflating: dataset/viratKohili/vk-4.jpeg  \n",
            "  inflating: dataset/viratKohili/vk-5.jpeg  \n",
            "  inflating: dataset/viratKohili/vk-6.jpeg  \n",
            "  inflating: dataset/viratKohili/vk-7.jpg  \n",
            "  inflating: dataset/viratKohili/vk-8.jpeg  \n",
            "  inflating: dataset/viratKohili/vk-9.jpg  \n",
            "   creating: dataset/Yuvraj/\n",
            "  inflating: dataset/Yuvraj/uv-1.jpg  \n",
            "  inflating: dataset/Yuvraj/uv-10.jpg  \n",
            "  inflating: dataset/Yuvraj/uv-2.jpg  \n",
            "  inflating: dataset/Yuvraj/uv-3.jpg  \n",
            "  inflating: dataset/Yuvraj/uv-4.jpeg  \n",
            "  inflating: dataset/Yuvraj/uv-5.jpg  \n",
            "  inflating: dataset/Yuvraj/uv-6.jpg  \n",
            "  inflating: dataset/Yuvraj/uv-7.jpg  \n",
            "  inflating: dataset/Yuvraj/uv-8.jpg  \n",
            "  inflating: dataset/Yuvraj/uv-9.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oun6DPoY7MLH",
        "colab_type": "code",
        "outputId": "9196933b-bacb-436e-b9cf-fcc449775382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# face detection model paths\n",
        "protoPath = os.getcwd()+\"/deploy.prototxt.txt\"\n",
        "modelPath = os.getcwd()+\"/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "\n",
        "# loading detection model\n",
        "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
        "\n",
        "# load embedding model\n",
        "embedder = embedding.InceptionResnetV1(pretrained='vggface2').eval()\n",
        "\n",
        "# paths to save pickle files\n",
        "currentDir = os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading parameters (1/2)\n",
            "Downloading parameters (2/2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lw2OaiP8Bp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# images folder\n",
        "dataset = os.path.join(currentDir, \"dataset\")\n",
        "\n",
        "# paths to save pickle files\n",
        "!mkdir output\n",
        "!touch  /content/output/SimpleEmbeddings.pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZCfFbzb8JC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "2# getting all images paths\n",
        "\n",
        "imagePaths = []\n",
        "\n",
        "for person in os.listdir(dataset):\n",
        "  for img in os.listdir(dataset+\"/\"+person):\n",
        "    imagePaths.append(dataset+\"/\"+person+\"/\"+img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtlsxgLk9KAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create lists to append ImgPaths/names/imageIDs/boxs/embeddings\n",
        "ImgPaths = []\n",
        "names = []\n",
        "imageIDs = []\n",
        "boxs = []\n",
        "embeddings = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuPyXT_Z9OXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initlize the total number of faces processed\n",
        "total = 0\n",
        "\n",
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "  \n",
        "    #print(i,imagePath)\n",
        "    \n",
        "    #extract the person name from the image path\n",
        "    \n",
        "    name = imagePath.split(os.path.sep)[-2]\n",
        "    imageID = imagePath.split(os.path.sep)[-1].split('.')[-2]\n",
        "    \n",
        "    image = cv2.imread(imagePath)\n",
        "    (h,w) = image.shape[:2]\n",
        "    \n",
        "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "    \n",
        "    detector.setInput(blob)\n",
        "    detections = detector.forward()\n",
        "    \n",
        "    if len(detections) > 0:\n",
        "        \n",
        "        # we're making the assumption that each image has only ONE\n",
        "        # face, so find the bounding box with the largest probalility\n",
        "        \n",
        "        i = np.argmax(detections[0, 0, :, 2])\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        \n",
        "        # ensure that the detection with the largest probability also\n",
        "        # means our minimum probability test (thus helping filter out\n",
        "        # weak detections)\n",
        "        \n",
        "        if confidence > 0.5:\n",
        "            \n",
        "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "            \n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "            \n",
        "            face = image[startY:endY , startX:endX]\n",
        "            (fH , fW) = face.shape[:2]\n",
        "            \n",
        "            \n",
        "            # ensure the facce width and height are sufficently large\n",
        "            if fW < 20 or fH < 20:\n",
        "                continue\n",
        "                \n",
        "            try:\n",
        "                faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255,(160, 160), (0, 0, 0), swapRB=True, crop=False)\n",
        "            except:\n",
        "                print(\"[Error] - Face size in Image not sufficent to get Embeddings : \", imagePath)\n",
        "                continue\n",
        "            \n",
        "            faceTensor = torch.tensor(faceBlob)\n",
        "            faceEmbed = embedder(faceTensor)\n",
        "            flattenEmbed = faceEmbed.squeeze(0).detach().numpy()\n",
        "            \n",
        "            ImgPaths.append(imagePath)\n",
        "            imageIDs.append(imageID)\n",
        "            names.append(name)\n",
        "            boxs.append(box)\n",
        "            embeddings.append(flattenEmbed)\n",
        "            total += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttXo2Ioy-KBn",
        "colab_type": "code",
        "outputId": "f0de311b-1c7a-4c57-a561-b49a08d07736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# dump the facial embeddings + names to disk\n",
        "print(\"[INFO] serializing {} encodings ....\".format(total))\n",
        "data = {\"paths\":ImgPaths, \"names\":names, \"imageIDs\":imageIDs, \"boxs\":boxs, \"embeddings\":embeddings}\n",
        "with open(embeddingPickle , \"wb\") as f:\n",
        "  pickle.dump(data,f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] serializing 176 encodings ....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HezAdkzVBbG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# paths to embedding pickle file\n",
        "embeddingPickle = \"./output/SimpleEmbeddings.pickle\"\n",
        "\n",
        "# path to recognizer pickle file\n",
        "!touch /content/output/SimpleRecognizer.pickle\n",
        "recognizerPickle = \"./output/SimpleRecognizer.pickle\"\n",
        "\n",
        "# path to labels pickle file\n",
        "!touch /content/output/SimpleLabel.pickle\n",
        "labelPickle = \"./output/SimpleLabel.pickle\"\n",
        "\n",
        "# loading embeddings pickle\n",
        "data = pickle.loads(open(embeddingPickle, \"rb\").read())\n",
        "\n",
        "# encode the labels\n",
        "label = LabelEncoder()\n",
        "labels = label.fit_transform(data[\"names\"])\n",
        "\n",
        "# getting embeddings\n",
        "Embeddings = np.array(data[\"embeddings\"])\n",
        "\n",
        "# train the model used to accept the 512-d embeddings of the face and \n",
        "# then produce the actual face recognition\n",
        "\n",
        "recognizer = KNeighborsClassifier(n_neighbors= 2, metric='euclidean', weights=\"distance\")\n",
        "#recognizer = SVC(probability=True)\n",
        "recognizer.fit(Embeddings, labels)\n",
        "\n",
        "# write the actual face recognition model to disk\n",
        "f = open(recognizerPickle, \"wb\")\n",
        "f.write(pickle.dumps(recognizer))\n",
        "f.close()\n",
        "\n",
        "# write the label encoder to disk\n",
        "f = open(labelPickle,\"wb\")\n",
        "f.write(pickle.dumps(label))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH19Lo__E--a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading face detection model\n",
        "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
        "\n",
        "# load embedding model\n",
        "embedder = embedding.InceptionResnetV1(pretrained=\"vggface2\").eval()\n",
        "\n",
        "# load the actual face recognition model along with the label encoder\n",
        "recognizer = pickle.loads(open(recognizerPickle, \"rb\").read())\n",
        "label = pickle.loads(open(labelPickle, \"rb\").read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBS5V1eBFiyr",
        "colab_type": "code",
        "outputId": "17322f9b-a90f-4e6d-986a-17f53f8d45f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "imagePath = os.getcwd() + \"/test1.jpg\"\n",
        "\n",
        "predictedImg = os.getcwd()\n",
        "\n",
        "image = cv2.imread(imagePath)\n",
        "(h,w) = image.shape[:2]\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "\n",
        "detector.setInput(blob)\n",
        "detections = detector.forward()\n",
        "\n",
        "# loop over the detections\n",
        "for i in range(0, detections.shape[2]):\n",
        "    \n",
        "    # extract the confidence (i.e., probalility) associated with the prediction\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "    \n",
        "    # fillter out weak detections\n",
        "    if confidence > 0.2:\n",
        "        \n",
        "        # compute the (x ,y) - coordinates of the bounding box for the face\n",
        "        \n",
        "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "        \n",
        "        # extract the face ROI\n",
        "        face = image[startY:endY , startX:endX]\n",
        "        (fH ,fW) = face.shape[:2]\n",
        "        \n",
        "        # ensure the facce width and height are sufficently large\n",
        "        if fW < 20 or fH < 20:\n",
        "            print(\"[Error] - Face size in Image not sufficent to get Embeddings : \", imagePath)\n",
        "            continue\n",
        "        \n",
        "\n",
        "        try:\n",
        "            faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255,(160, 160), (0, 0, 0), swapRB=True, crop=False)\n",
        "        except:\n",
        "            print(\"[Error] - Face size in Image not sufficent to get Embeddings : \", imagePath)\n",
        "            continue\n",
        "        \n",
        "        faceTensor = torch.tensor(faceBlob)\n",
        "        faceEmbed = embedder(faceTensor)\n",
        "        flattenEmbed = faceEmbed.squeeze(0).detach().numpy()\n",
        "        \n",
        "        array = np.array(flattenEmbed).reshape(1,-1)\n",
        "        \n",
        "        # perform classification to recognize the face\n",
        "        \n",
        "        preds = recognizer.predict_proba(array)[0]\n",
        "        \n",
        "        j = np.argmax(preds)\n",
        "        \n",
        "        proba = preds[j]\n",
        "        name = label.classes_[j]\n",
        "        \n",
        "        #draw the bunding box of the face along with the associated probability\n",
        "        \n",
        "        text = \"{}: {:.2f}%\".format(name, proba * 100)\n",
        "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "        \n",
        "        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "        \n",
        "        cv2.putText(image, text, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.50, (255, 255, 255), 1)\n",
        "        \n",
        "# save image predicte folder\n",
        "cv2.imwrite(\"{}/test_prediction.png\".format(predictedImg), image)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIYFDJNEoJzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}